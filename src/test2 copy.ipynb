{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_video, read_video_timestamps\n",
    "\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from kornia_moons.feature import *\n",
    "from kornia.contrib import ImageStitcher\n",
    "from kornia.geometry.transform import warp_perspective, get_perspective_transform\n",
    "\n",
    "import utils\n",
    "def load_torch_image(fname):\n",
    "    img = K.image_to_tensor(cv2.imread(fname), False).float() /255.\n",
    "    img = K.color.bgr_to_rgb(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../deep-stabilization/dvs/video/s_114_outdoor_running_trail_daytime/ControlCam_20200930_104820.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames, audio_frames, meta = read_video(fname, end_pts=100, pts_unit=\"sec\")\n",
    "print(meta)\n",
    "print(\"video size: \", video_frames.shape)\n",
    "print(\"audio size: \", audio_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(fname, width=960, height=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"../test.mp4\", width=960, height=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"../video_out.avi\", width=960, height=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.show_frames(video_frames[:100:10], 2, 5, (30,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = video_frames[0:1].permute(0,3,1,2).float() / 255\n",
    "img2 = video_frames[100:101].permute(0,3,1,2).float() / 255\n",
    "\n",
    "print(img1.shape)\n",
    "\n",
    "feature1 = transforms.CenterCrop((270*3,480*3))(img1)\n",
    "feature2 = transforms.CenterCrop((270*3,480*3))(img2)\n",
    "\n",
    "feature1 = torch.cat(transforms.FiveCrop(256)(feature1))\n",
    "feature2 = torch.cat(transforms.FiveCrop(256)(feature2))\n",
    "\n",
    "print(feature1.shape)\n",
    "\n",
    "# K.color.rgb_to_grayscale(img1).shape\n",
    "utils.show_frame(feature1[3].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher2 = KF.LocalFeatureMatcher(\n",
    "    KF.SIFTFeature(2000, device=\"cuda\"),\n",
    "    KF.DescriptorMatcher('smnn', 0.9)\n",
    "    )\n",
    "\n",
    "input_dict = {\"image0\": K.color.rgb_to_grayscale(feature1).cuda(), # LofTR works on grayscale images only \n",
    "              \"image1\": K.color.rgb_to_grayscale(feature2).cuda()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    correspondences = matcher2(input_dict)\n",
    "    del input_dict[\"image0\"], input_dict[\"image1\"]\n",
    "    \n",
    "for k,v in correspondences.items():\n",
    "    print (k)\n",
    "\n",
    "print(len(correspondences[\"keypoints0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(5):\n",
    "#     idx = torch.topk(correspondences[\"confidence\"][correspondences[\"batch_indexes\"]==x], 100).indices\n",
    "#     print((correspondences[\"keypoints0\"][correspondences[\"batch_indexes\"]==x][idx] - correspondences[\"keypoints1\"][correspondences[\"batch_indexes\"]==x][idx]).mean(dim=0))\n",
    "# print(\"\\n\\n\\n\")\n",
    "# for x in range(5):\n",
    "#     idx = torch.topk(correspondences[\"confidence\"][correspondences[\"batch_indexes\"]==x], 150).indices\n",
    "#     print((correspondences[\"keypoints0\"][correspondences[\"batch_indexes\"]==x][idx] - correspondences[\"keypoints1\"][correspondences[\"batch_indexes\"]==x][idx]).mean(dim=0))\n",
    "# print(\"\\n\\n\\n\")\n",
    "tmp = []\n",
    "for x in range(5):\n",
    "    tmp.append((correspondences[\"keypoints0\"][correspondences[\"batch_indexes\"]==x] - correspondences[\"keypoints1\"][correspondences[\"batch_indexes\"]==x]).median(dim=0)[0])\n",
    "    print(tmp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.Tensor([\n",
    "    [135*1+128, 240*1+128],# 左上\n",
    "    [135*1+128, 240*7-128],# 右上\n",
    "    [135*7-128, 240*1+128],# 左下\n",
    "    [135*7-128, 240*7-128] # 右下\n",
    "]).cuda()\n",
    "\n",
    "dst = torch.vstack(tmp[:4]) + src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1[0].permute(1,2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cv2.warpAffine(img1[0].permute(1,2,0).numpy(), H[:2], (1080, 1920))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_frame(torch.from_numpy(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.5, 0.999, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src)\n",
    "print(dst)\n",
    "b = get_perspective_transform(src.unsqueeze(0), dst.unsqueeze(0))\n",
    "\n",
    "out = warp_perspective(img1.cuda(), b, (1080,1920)).cpu()\n",
    "outt = torch.where(out == 0.0, img2, out)\n",
    "utils.show_frame(outt[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_frame(img1[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_frame(img2[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = warp_perspective(img1.cuda(), torch.from_numpy(H).cuda().unsqueeze(0).float(), (1080,1920)).cpu()\n",
    "outtt = torch.where(out == 0.0, img2, out)\n",
    "utils.show_frame(outtt[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in correspondences.items():\n",
    "    print (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = torch.quantile(correspondences[\"confidence\"], 0.0)\n",
    "idx = correspondences[\"confidence\"] > th\n",
    "print(idx.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkpts0 = correspondences['keypoints0'][idx].cpu().numpy()\n",
    "mkpts1 = correspondences['keypoints1'][idx].cpu().numpy()\n",
    "H, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.5, 0.999, 100000)\n",
    "inliers = inliers > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_LAF_matches(\n",
    "    KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0).view(1,-1, 2),\n",
    "                                torch.ones(mkpts0.shape[0]).view(1,-1, 1, 1),\n",
    "                                torch.ones(mkpts0.shape[0]).view(1,-1, 1)),\n",
    "\n",
    "    KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n",
    "                                torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n",
    "                                torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n",
    "    torch.arange(mkpts0.shape[0]).view(-1,1).repeat(1,2),\n",
    "    K.tensor_to_image(img1),\n",
    "    K.tensor_to_image(img2),\n",
    "    inliers,\n",
    "    draw_dict={'inlier_color': (0.2, 1, 0.2),\n",
    "               'tentative_color': None, \n",
    "               'feature_color': (0.2, 0.5, 1), 'vertical': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.geometry.transform import get_perspective_transform, warp_perspective\n",
    "idx = torch.topk(correspondences[\"confidence\"], 12).indices\n",
    "# idx = torch.randperm(20)\n",
    "src = correspondences[\"keypoints0\"][idx[:4]].unsqueeze(0)\n",
    "dst = correspondences[\"keypoints1\"][idx[:4]].unsqueeze(0)\n",
    "a = get_perspective_transform(src, dst)\n",
    "src = correspondences[\"keypoints0\"][idx[2:6]].unsqueeze(0)\n",
    "dst = correspondences[\"keypoints1\"][idx[2:6]].unsqueeze(0)\n",
    "b = get_perspective_transform(src, dst)\n",
    "\n",
    "out = warp_perspective(img1.cuda(), (a+b)/2, (1080//4,1920//4)).cpu()\n",
    "outt = torch.where(out < 0.0, img2, out)\n",
    "utils.show_frame(outt[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 1080\n",
      "Frame: 0/486 -  Tracked points : 311\n",
      "Frame: 1/486 -  Tracked points : 258\n",
      "Frame: 2/486 -  Tracked points : 284\n",
      "Frame: 3/486 -  Tracked points : 222\n",
      "Frame: 4/486 -  Tracked points : 289\n",
      "Frame: 5/486 -  Tracked points : 214\n",
      "Frame: 6/486 -  Tracked points : 247\n",
      "Frame: 7/486 -  Tracked points : 293\n",
      "Frame: 8/486 -  Tracked points : 328\n",
      "Frame: 9/486 -  Tracked points : 246\n",
      "Frame: 10/486 -  Tracked points : 303\n",
      "Frame: 11/486 -  Tracked points : 333\n",
      "Frame: 12/486 -  Tracked points : 308\n",
      "Frame: 13/486 -  Tracked points : 288\n",
      "Frame: 14/486 -  Tracked points : 304\n",
      "Frame: 15/486 -  Tracked points : 285\n",
      "Frame: 16/486 -  Tracked points : 288\n",
      "Frame: 17/486 -  Tracked points : 283\n",
      "Frame: 18/486 -  Tracked points : 284\n",
      "Frame: 19/486 -  Tracked points : 140\n",
      "Frame: 20/486 -  Tracked points : 181\n",
      "Frame: 21/486 -  Tracked points : 197\n",
      "Frame: 22/486 -  Tracked points : 162\n",
      "Frame: 23/486 -  Tracked points : 303\n",
      "Frame: 24/486 -  Tracked points : 319\n",
      "Frame: 25/486 -  Tracked points : 233\n",
      "Frame: 26/486 -  Tracked points : 204\n",
      "Frame: 27/486 -  Tracked points : 268\n",
      "Frame: 28/486 -  Tracked points : 275\n",
      "Frame: 29/486 -  Tracked points : 299\n",
      "Frame: 30/486 -  Tracked points : 203\n",
      "Frame: 31/486 -  Tracked points : 258\n",
      "Frame: 32/486 -  Tracked points : 241\n",
      "Frame: 33/486 -  Tracked points : 255\n",
      "Frame: 34/486 -  Tracked points : 236\n",
      "Frame: 35/486 -  Tracked points : 265\n",
      "Frame: 36/486 -  Tracked points : 162\n",
      "Frame: 37/486 -  Tracked points : 71\n",
      "Frame: 38/486 -  Tracked points : 69\n",
      "Frame: 39/486 -  Tracked points : 78\n",
      "Frame: 40/486 -  Tracked points : 71\n",
      "Frame: 41/486 -  Tracked points : 77\n",
      "Frame: 42/486 -  Tracked points : 68\n",
      "Frame: 43/486 -  Tracked points : 78\n",
      "Frame: 44/486 -  Tracked points : 57\n",
      "Frame: 45/486 -  Tracked points : 74\n",
      "Frame: 46/486 -  Tracked points : 63\n",
      "Frame: 47/486 -  Tracked points : 73\n",
      "Frame: 48/486 -  Tracked points : 75\n",
      "Frame: 49/486 -  Tracked points : 81\n",
      "Frame: 50/486 -  Tracked points : 84\n",
      "Frame: 51/486 -  Tracked points : 82\n",
      "Frame: 52/486 -  Tracked points : 82\n",
      "Frame: 53/486 -  Tracked points : 372\n",
      "Frame: 54/486 -  Tracked points : 276\n",
      "Frame: 55/486 -  Tracked points : 216\n",
      "Frame: 56/486 -  Tracked points : 136\n",
      "Frame: 57/486 -  Tracked points : 336\n",
      "Frame: 58/486 -  Tracked points : 338\n",
      "Frame: 59/486 -  Tracked points : 381\n",
      "Frame: 60/486 -  Tracked points : 339\n",
      "Frame: 61/486 -  Tracked points : 323\n",
      "Frame: 62/486 -  Tracked points : 299\n",
      "Frame: 63/486 -  Tracked points : 319\n",
      "Frame: 64/486 -  Tracked points : 360\n",
      "Frame: 65/486 -  Tracked points : 278\n",
      "Frame: 66/486 -  Tracked points : 223\n",
      "Frame: 67/486 -  Tracked points : 206\n",
      "Frame: 68/486 -  Tracked points : 198\n",
      "Frame: 69/486 -  Tracked points : 168\n",
      "Frame: 70/486 -  Tracked points : 175\n",
      "Frame: 71/486 -  Tracked points : 161\n",
      "Frame: 72/486 -  Tracked points : 155\n",
      "Frame: 73/486 -  Tracked points : 151\n",
      "Frame: 74/486 -  Tracked points : 178\n",
      "Frame: 75/486 -  Tracked points : 178\n",
      "Frame: 76/486 -  Tracked points : 173\n",
      "Frame: 77/486 -  Tracked points : 193\n",
      "Frame: 78/486 -  Tracked points : 151\n",
      "Frame: 79/486 -  Tracked points : 136\n",
      "Frame: 80/486 -  Tracked points : 190\n",
      "Frame: 81/486 -  Tracked points : 211\n",
      "Frame: 82/486 -  Tracked points : 247\n",
      "Frame: 83/486 -  Tracked points : 211\n",
      "Frame: 84/486 -  Tracked points : 191\n",
      "Frame: 85/486 -  Tracked points : 116\n",
      "Frame: 86/486 -  Tracked points : 153\n",
      "Frame: 87/486 -  Tracked points : 132\n",
      "Frame: 88/486 -  Tracked points : 133\n",
      "Frame: 89/486 -  Tracked points : 135\n",
      "Frame: 90/486 -  Tracked points : 140\n",
      "Frame: 91/486 -  Tracked points : 107\n",
      "Frame: 92/486 -  Tracked points : 164\n",
      "Frame: 93/486 -  Tracked points : 151\n",
      "Frame: 94/486 -  Tracked points : 170\n",
      "Frame: 95/486 -  Tracked points : 181\n",
      "Frame: 96/486 -  Tracked points : 183\n",
      "Frame: 97/486 -  Tracked points : 154\n",
      "Frame: 98/486 -  Tracked points : 132\n",
      "Frame: 99/486 -  Tracked points : 142\n",
      "Frame: 100/486 -  Tracked points : 119\n",
      "Frame: 101/486 -  Tracked points : 158\n",
      "Frame: 102/486 -  Tracked points : 149\n",
      "Frame: 103/486 -  Tracked points : 145\n",
      "Frame: 104/486 -  Tracked points : 177\n",
      "Frame: 105/486 -  Tracked points : 128\n",
      "Frame: 106/486 -  Tracked points : 139\n",
      "Frame: 107/486 -  Tracked points : 109\n",
      "Frame: 108/486 -  Tracked points : 109\n",
      "Frame: 109/486 -  Tracked points : 117\n",
      "Frame: 110/486 -  Tracked points : 105\n",
      "Frame: 111/486 -  Tracked points : 169\n",
      "Frame: 112/486 -  Tracked points : 102\n",
      "Frame: 113/486 -  Tracked points : 104\n",
      "Frame: 114/486 -  Tracked points : 112\n",
      "Frame: 115/486 -  Tracked points : 121\n",
      "Frame: 116/486 -  Tracked points : 118\n",
      "Frame: 117/486 -  Tracked points : 124\n",
      "Frame: 118/486 -  Tracked points : 103\n",
      "Frame: 119/486 -  Tracked points : 105\n",
      "Frame: 120/486 -  Tracked points : 121\n",
      "Frame: 121/486 -  Tracked points : 75\n",
      "Frame: 122/486 -  Tracked points : 47\n",
      "Frame: 123/486 -  Tracked points : 55\n",
      "Frame: 124/486 -  Tracked points : 51\n",
      "Frame: 125/486 -  Tracked points : 76\n",
      "Frame: 126/486 -  Tracked points : 78\n",
      "Frame: 127/486 -  Tracked points : 62\n",
      "Frame: 128/486 -  Tracked points : 64\n",
      "Frame: 129/486 -  Tracked points : 81\n",
      "Frame: 130/486 -  Tracked points : 86\n",
      "Frame: 131/486 -  Tracked points : 83\n",
      "Frame: 132/486 -  Tracked points : 81\n",
      "Frame: 133/486 -  Tracked points : 82\n",
      "Frame: 134/486 -  Tracked points : 100\n",
      "Frame: 135/486 -  Tracked points : 123\n",
      "Frame: 136/486 -  Tracked points : 144\n",
      "Frame: 137/486 -  Tracked points : 118\n",
      "Frame: 138/486 -  Tracked points : 119\n",
      "Frame: 139/486 -  Tracked points : 119\n",
      "Frame: 140/486 -  Tracked points : 138\n",
      "Frame: 141/486 -  Tracked points : 110\n",
      "Frame: 142/486 -  Tracked points : 146\n",
      "Frame: 143/486 -  Tracked points : 113\n",
      "Frame: 144/486 -  Tracked points : 128\n",
      "Frame: 145/486 -  Tracked points : 106\n",
      "Frame: 146/486 -  Tracked points : 120\n",
      "Frame: 147/486 -  Tracked points : 77\n",
      "Frame: 148/486 -  Tracked points : 130\n",
      "Frame: 149/486 -  Tracked points : 144\n",
      "Frame: 150/486 -  Tracked points : 233\n",
      "Frame: 151/486 -  Tracked points : 186\n",
      "Frame: 152/486 -  Tracked points : 45\n",
      "Frame: 153/486 -  Tracked points : 43\n",
      "Frame: 154/486 -  Tracked points : 42\n",
      "Frame: 155/486 -  Tracked points : 80\n",
      "Frame: 156/486 -  Tracked points : 86\n",
      "Frame: 157/486 -  Tracked points : 115\n",
      "Frame: 158/486 -  Tracked points : 117\n",
      "Frame: 159/486 -  Tracked points : 121\n",
      "Frame: 160/486 -  Tracked points : 123\n",
      "Frame: 161/486 -  Tracked points : 151\n",
      "Frame: 162/486 -  Tracked points : 126\n",
      "Frame: 163/486 -  Tracked points : 148\n",
      "Frame: 164/486 -  Tracked points : 111\n",
      "Frame: 165/486 -  Tracked points : 110\n",
      "Frame: 166/486 -  Tracked points : 116\n",
      "Frame: 167/486 -  Tracked points : 100\n",
      "Frame: 168/486 -  Tracked points : 113\n",
      "Frame: 169/486 -  Tracked points : 110\n",
      "Frame: 170/486 -  Tracked points : 112\n",
      "Frame: 171/486 -  Tracked points : 85\n",
      "Frame: 172/486 -  Tracked points : 93\n",
      "Frame: 173/486 -  Tracked points : 75\n",
      "Frame: 174/486 -  Tracked points : 68\n",
      "Frame: 175/486 -  Tracked points : 83\n",
      "Frame: 176/486 -  Tracked points : 83\n",
      "Frame: 177/486 -  Tracked points : 68\n",
      "Frame: 178/486 -  Tracked points : 103\n",
      "Frame: 179/486 -  Tracked points : 88\n",
      "Frame: 180/486 -  Tracked points : 97\n",
      "Frame: 181/486 -  Tracked points : 91\n",
      "Frame: 182/486 -  Tracked points : 100\n",
      "Frame: 183/486 -  Tracked points : 111\n",
      "Frame: 184/486 -  Tracked points : 72\n",
      "Frame: 185/486 -  Tracked points : 56\n",
      "Frame: 186/486 -  Tracked points : 90\n",
      "Frame: 187/486 -  Tracked points : 76\n",
      "Frame: 188/486 -  Tracked points : 90\n",
      "Frame: 189/486 -  Tracked points : 181\n",
      "Frame: 190/486 -  Tracked points : 106\n",
      "Frame: 191/486 -  Tracked points : 92\n",
      "Frame: 192/486 -  Tracked points : 388\n",
      "Frame: 193/486 -  Tracked points : 382\n",
      "Frame: 194/486 -  Tracked points : 387\n",
      "Frame: 195/486 -  Tracked points : 390\n",
      "Frame: 196/486 -  Tracked points : 384\n",
      "Frame: 197/486 -  Tracked points : 389\n",
      "Frame: 198/486 -  Tracked points : 385\n",
      "Frame: 199/486 -  Tracked points : 390\n",
      "Frame: 200/486 -  Tracked points : 127\n",
      "Frame: 201/486 -  Tracked points : 190\n",
      "Frame: 202/486 -  Tracked points : 107\n",
      "Frame: 203/486 -  Tracked points : 145\n",
      "Frame: 204/486 -  Tracked points : 137\n",
      "Frame: 205/486 -  Tracked points : 205\n",
      "Frame: 206/486 -  Tracked points : 146\n",
      "Frame: 207/486 -  Tracked points : 170\n",
      "Frame: 208/486 -  Tracked points : 205\n",
      "Frame: 209/486 -  Tracked points : 133\n",
      "Frame: 210/486 -  Tracked points : 74\n",
      "Frame: 211/486 -  Tracked points : 168\n",
      "Frame: 212/486 -  Tracked points : 127\n",
      "Frame: 213/486 -  Tracked points : 384\n",
      "Frame: 214/486 -  Tracked points : 378\n",
      "Frame: 215/486 -  Tracked points : 376\n",
      "Frame: 216/486 -  Tracked points : 385\n",
      "Frame: 217/486 -  Tracked points : 386\n",
      "Frame: 218/486 -  Tracked points : 396\n",
      "Frame: 219/486 -  Tracked points : 389\n",
      "Frame: 220/486 -  Tracked points : 378\n",
      "Frame: 221/486 -  Tracked points : 379\n",
      "Frame: 222/486 -  Tracked points : 382\n",
      "Frame: 223/486 -  Tracked points : 384\n",
      "Frame: 224/486 -  Tracked points : 387\n",
      "Frame: 225/486 -  Tracked points : 385\n",
      "Frame: 226/486 -  Tracked points : 384\n",
      "Frame: 227/486 -  Tracked points : 392\n",
      "Frame: 228/486 -  Tracked points : 392\n",
      "Frame: 229/486 -  Tracked points : 393\n",
      "Frame: 230/486 -  Tracked points : 394\n",
      "Frame: 231/486 -  Tracked points : 347\n",
      "Frame: 232/486 -  Tracked points : 291\n",
      "Frame: 233/486 -  Tracked points : 389\n",
      "Frame: 234/486 -  Tracked points : 378\n",
      "Frame: 235/486 -  Tracked points : 390\n",
      "Frame: 236/486 -  Tracked points : 369\n",
      "Frame: 237/486 -  Tracked points : 384\n",
      "Frame: 238/486 -  Tracked points : 384\n",
      "Frame: 239/486 -  Tracked points : 386\n",
      "Frame: 240/486 -  Tracked points : 206\n",
      "Frame: 241/486 -  Tracked points : 303\n",
      "Frame: 242/486 -  Tracked points : 291\n",
      "Frame: 243/486 -  Tracked points : 387\n",
      "Frame: 244/486 -  Tracked points : 384\n",
      "Frame: 245/486 -  Tracked points : 378\n",
      "Frame: 246/486 -  Tracked points : 380\n",
      "Frame: 247/486 -  Tracked points : 381\n",
      "Frame: 248/486 -  Tracked points : 383\n",
      "Frame: 249/486 -  Tracked points : 389\n",
      "Frame: 250/486 -  Tracked points : 390\n",
      "Frame: 251/486 -  Tracked points : 392\n",
      "Frame: 252/486 -  Tracked points : 387\n",
      "Frame: 253/486 -  Tracked points : 243\n",
      "Frame: 254/486 -  Tracked points : 392\n",
      "Frame: 255/486 -  Tracked points : 379\n",
      "Frame: 256/486 -  Tracked points : 384\n",
      "Frame: 257/486 -  Tracked points : 366\n",
      "Frame: 258/486 -  Tracked points : 389\n",
      "Frame: 259/486 -  Tracked points : 373\n",
      "Frame: 260/486 -  Tracked points : 373\n",
      "Frame: 261/486 -  Tracked points : 383\n",
      "Frame: 262/486 -  Tracked points : 376\n",
      "Frame: 263/486 -  Tracked points : 378\n",
      "Frame: 264/486 -  Tracked points : 379\n",
      "Frame: 265/486 -  Tracked points : 393\n",
      "Frame: 266/486 -  Tracked points : 394\n",
      "Frame: 267/486 -  Tracked points : 390\n",
      "Frame: 268/486 -  Tracked points : 383\n",
      "Frame: 269/486 -  Tracked points : 386\n",
      "Frame: 270/486 -  Tracked points : 394\n",
      "Frame: 271/486 -  Tracked points : 391\n",
      "Frame: 272/486 -  Tracked points : 362\n",
      "Frame: 273/486 -  Tracked points : 303\n",
      "Frame: 274/486 -  Tracked points : 236\n",
      "Frame: 275/486 -  Tracked points : 336\n",
      "Frame: 276/486 -  Tracked points : 295\n",
      "Frame: 277/486 -  Tracked points : 388\n",
      "Frame: 278/486 -  Tracked points : 371\n",
      "Frame: 279/486 -  Tracked points : 381\n",
      "Frame: 280/486 -  Tracked points : 386\n",
      "Frame: 281/486 -  Tracked points : 384\n",
      "Frame: 282/486 -  Tracked points : 375\n",
      "Frame: 283/486 -  Tracked points : 367\n",
      "Frame: 284/486 -  Tracked points : 391\n",
      "Frame: 285/486 -  Tracked points : 392\n",
      "Frame: 286/486 -  Tracked points : 389\n",
      "Frame: 287/486 -  Tracked points : 387\n",
      "Frame: 288/486 -  Tracked points : 392\n",
      "Frame: 289/486 -  Tracked points : 389\n",
      "Frame: 290/486 -  Tracked points : 385\n",
      "Frame: 291/486 -  Tracked points : 394\n",
      "Frame: 292/486 -  Tracked points : 392\n",
      "Frame: 293/486 -  Tracked points : 387\n",
      "Frame: 294/486 -  Tracked points : 389\n",
      "Frame: 295/486 -  Tracked points : 391\n",
      "Frame: 296/486 -  Tracked points : 369\n",
      "Frame: 297/486 -  Tracked points : 376\n",
      "Frame: 298/486 -  Tracked points : 387\n",
      "Frame: 299/486 -  Tracked points : 375\n",
      "Frame: 300/486 -  Tracked points : 365\n",
      "Frame: 301/486 -  Tracked points : 323\n",
      "Frame: 302/486 -  Tracked points : 291\n",
      "Frame: 303/486 -  Tracked points : 313\n",
      "Frame: 304/486 -  Tracked points : 324\n",
      "Frame: 305/486 -  Tracked points : 380\n",
      "Frame: 306/486 -  Tracked points : 393\n",
      "Frame: 307/486 -  Tracked points : 316\n",
      "Frame: 308/486 -  Tracked points : 391\n",
      "Frame: 309/486 -  Tracked points : 394\n",
      "Frame: 310/486 -  Tracked points : 294\n",
      "Frame: 311/486 -  Tracked points : 352\n",
      "Frame: 312/486 -  Tracked points : 390\n",
      "Frame: 313/486 -  Tracked points : 365\n",
      "Frame: 314/486 -  Tracked points : 390\n",
      "Frame: 315/486 -  Tracked points : 299\n",
      "Frame: 316/486 -  Tracked points : 255\n",
      "Frame: 317/486 -  Tracked points : 360\n",
      "Frame: 318/486 -  Tracked points : 389\n",
      "Frame: 319/486 -  Tracked points : 377\n",
      "Frame: 320/486 -  Tracked points : 379\n",
      "Frame: 321/486 -  Tracked points : 360\n",
      "Frame: 322/486 -  Tracked points : 381\n",
      "Frame: 323/486 -  Tracked points : 392\n",
      "Frame: 324/486 -  Tracked points : 381\n",
      "Frame: 325/486 -  Tracked points : 383\n",
      "Frame: 326/486 -  Tracked points : 381\n",
      "Frame: 327/486 -  Tracked points : 378\n",
      "Frame: 328/486 -  Tracked points : 388\n",
      "Frame: 329/486 -  Tracked points : 379\n",
      "Frame: 330/486 -  Tracked points : 389\n",
      "Frame: 331/486 -  Tracked points : 398\n",
      "Frame: 332/486 -  Tracked points : 393\n",
      "Frame: 333/486 -  Tracked points : 387\n",
      "Frame: 334/486 -  Tracked points : 391\n",
      "Frame: 335/486 -  Tracked points : 392\n",
      "Frame: 336/486 -  Tracked points : 391\n",
      "Frame: 337/486 -  Tracked points : 392\n",
      "Frame: 338/486 -  Tracked points : 391\n",
      "Frame: 339/486 -  Tracked points : 383\n",
      "Frame: 340/486 -  Tracked points : 385\n",
      "Frame: 341/486 -  Tracked points : 386\n",
      "Frame: 342/486 -  Tracked points : 394\n",
      "Frame: 343/486 -  Tracked points : 392\n",
      "Frame: 344/486 -  Tracked points : 383\n",
      "Frame: 345/486 -  Tracked points : 393\n",
      "Frame: 346/486 -  Tracked points : 310\n",
      "Frame: 347/486 -  Tracked points : 270\n",
      "Frame: 348/486 -  Tracked points : 199\n",
      "Frame: 349/486 -  Tracked points : 173\n",
      "Frame: 350/486 -  Tracked points : 231\n",
      "Frame: 351/486 -  Tracked points : 271\n",
      "Frame: 352/486 -  Tracked points : 369\n",
      "Frame: 353/486 -  Tracked points : 374\n",
      "Frame: 354/486 -  Tracked points : 316\n",
      "Frame: 355/486 -  Tracked points : 349\n",
      "Frame: 356/486 -  Tracked points : 290\n",
      "Frame: 357/486 -  Tracked points : 390\n",
      "Frame: 358/486 -  Tracked points : 382\n",
      "Frame: 359/486 -  Tracked points : 292\n",
      "Frame: 360/486 -  Tracked points : 252\n",
      "Frame: 361/486 -  Tracked points : 393\n",
      "Frame: 362/486 -  Tracked points : 382\n",
      "Frame: 363/486 -  Tracked points : 353\n",
      "Frame: 364/486 -  Tracked points : 383\n",
      "Frame: 365/486 -  Tracked points : 373\n",
      "Frame: 366/486 -  Tracked points : 387\n",
      "Frame: 367/486 -  Tracked points : 391\n",
      "Frame: 368/486 -  Tracked points : 385\n",
      "Frame: 369/486 -  Tracked points : 380\n",
      "Frame: 370/486 -  Tracked points : 394\n",
      "Frame: 371/486 -  Tracked points : 397\n",
      "Frame: 372/486 -  Tracked points : 149\n",
      "Frame: 373/486 -  Tracked points : 152\n",
      "Frame: 374/486 -  Tracked points : 108\n",
      "Frame: 375/486 -  Tracked points : 119\n",
      "Frame: 376/486 -  Tracked points : 151\n",
      "Frame: 377/486 -  Tracked points : 163\n",
      "Frame: 378/486 -  Tracked points : 147\n",
      "Frame: 379/486 -  Tracked points : 146\n",
      "Frame: 380/486 -  Tracked points : 130\n",
      "Frame: 381/486 -  Tracked points : 155\n",
      "Frame: 382/486 -  Tracked points : 119\n",
      "Frame: 383/486 -  Tracked points : 140\n",
      "Frame: 384/486 -  Tracked points : 106\n",
      "Frame: 385/486 -  Tracked points : 157\n",
      "Frame: 386/486 -  Tracked points : 152\n",
      "Frame: 387/486 -  Tracked points : 390\n",
      "Frame: 388/486 -  Tracked points : 174\n",
      "Frame: 389/486 -  Tracked points : 110\n",
      "Frame: 390/486 -  Tracked points : 120\n",
      "Frame: 391/486 -  Tracked points : 127\n",
      "Frame: 392/486 -  Tracked points : 147\n",
      "Frame: 393/486 -  Tracked points : 97\n",
      "Frame: 394/486 -  Tracked points : 100\n",
      "Frame: 395/486 -  Tracked points : 128\n",
      "Frame: 396/486 -  Tracked points : 95\n",
      "Frame: 397/486 -  Tracked points : 201\n",
      "Frame: 398/486 -  Tracked points : 188\n",
      "Frame: 399/486 -  Tracked points : 173\n",
      "Frame: 400/486 -  Tracked points : 174\n",
      "Frame: 401/486 -  Tracked points : 205\n",
      "Frame: 402/486 -  Tracked points : 245\n",
      "Frame: 403/486 -  Tracked points : 241\n",
      "Frame: 404/486 -  Tracked points : 180\n",
      "Frame: 405/486 -  Tracked points : 240\n",
      "Frame: 406/486 -  Tracked points : 231\n",
      "Frame: 407/486 -  Tracked points : 188\n",
      "Frame: 408/486 -  Tracked points : 148\n",
      "Frame: 409/486 -  Tracked points : 137\n",
      "Frame: 410/486 -  Tracked points : 179\n",
      "Frame: 411/486 -  Tracked points : 229\n",
      "Frame: 412/486 -  Tracked points : 162\n",
      "Frame: 413/486 -  Tracked points : 139\n",
      "Frame: 414/486 -  Tracked points : 188\n",
      "Frame: 415/486 -  Tracked points : 217\n",
      "Frame: 416/486 -  Tracked points : 197\n",
      "Frame: 417/486 -  Tracked points : 200\n",
      "Frame: 418/486 -  Tracked points : 197\n",
      "Frame: 419/486 -  Tracked points : 233\n",
      "Frame: 420/486 -  Tracked points : 150\n",
      "Frame: 421/486 -  Tracked points : 139\n",
      "Frame: 422/486 -  Tracked points : 135\n",
      "Frame: 423/486 -  Tracked points : 185\n",
      "Frame: 424/486 -  Tracked points : 165\n",
      "Frame: 425/486 -  Tracked points : 133\n",
      "Frame: 426/486 -  Tracked points : 140\n",
      "Frame: 427/486 -  Tracked points : 157\n",
      "Frame: 428/486 -  Tracked points : 220\n",
      "Frame: 429/486 -  Tracked points : 175\n",
      "Frame: 430/486 -  Tracked points : 152\n",
      "Frame: 431/486 -  Tracked points : 163\n",
      "Frame: 432/486 -  Tracked points : 167\n",
      "Frame: 433/486 -  Tracked points : 186\n",
      "Frame: 434/486 -  Tracked points : 198\n",
      "Frame: 435/486 -  Tracked points : 197\n",
      "Frame: 436/486 -  Tracked points : 194\n",
      "Frame: 437/486 -  Tracked points : 163\n",
      "Frame: 438/486 -  Tracked points : 133\n",
      "Frame: 439/486 -  Tracked points : 161\n",
      "Frame: 440/486 -  Tracked points : 175\n",
      "Frame: 441/486 -  Tracked points : 178\n",
      "Frame: 442/486 -  Tracked points : 184\n",
      "Frame: 443/486 -  Tracked points : 184\n",
      "Frame: 444/486 -  Tracked points : 180\n",
      "Frame: 445/486 -  Tracked points : 201\n",
      "Frame: 446/486 -  Tracked points : 162\n",
      "Frame: 447/486 -  Tracked points : 173\n",
      "Frame: 448/486 -  Tracked points : 199\n",
      "Frame: 449/486 -  Tracked points : 189\n",
      "Frame: 450/486 -  Tracked points : 156\n",
      "Frame: 451/486 -  Tracked points : 137\n",
      "Frame: 452/486 -  Tracked points : 150\n",
      "Frame: 453/486 -  Tracked points : 135\n",
      "Frame: 454/486 -  Tracked points : 154\n",
      "Frame: 455/486 -  Tracked points : 179\n",
      "Frame: 456/486 -  Tracked points : 148\n",
      "Frame: 457/486 -  Tracked points : 155\n",
      "Frame: 458/486 -  Tracked points : 183\n",
      "Frame: 459/486 -  Tracked points : 144\n",
      "Frame: 460/486 -  Tracked points : 134\n",
      "Frame: 461/486 -  Tracked points : 140\n",
      "Frame: 462/486 -  Tracked points : 205\n",
      "Frame: 463/486 -  Tracked points : 176\n",
      "Frame: 464/486 -  Tracked points : 163\n",
      "Frame: 465/486 -  Tracked points : 175\n",
      "Frame: 466/486 -  Tracked points : 183\n",
      "Frame: 467/486 -  Tracked points : 131\n",
      "Frame: 468/486 -  Tracked points : 142\n",
      "Frame: 469/486 -  Tracked points : 158\n",
      "Frame: 470/486 -  Tracked points : 131\n",
      "Frame: 471/486 -  Tracked points : 141\n",
      "Frame: 472/486 -  Tracked points : 138\n",
      "Frame: 473/486 -  Tracked points : 143\n",
      "Frame: 474/486 -  Tracked points : 128\n",
      "Frame: 475/486 -  Tracked points : 118\n",
      "Frame: 476/486 -  Tracked points : 108\n",
      "Frame: 477/486 -  Tracked points : 106\n",
      "Frame: 478/486 -  Tracked points : 114\n",
      "Frame: 479/486 -  Tracked points : 138\n",
      "Frame: 480/486 -  Tracked points : 144\n",
      "Frame: 481/486 -  Tracked points : 130\n",
      "Frame: 482/486 -  Tracked points : 131\n",
      "Frame: 483/486 -  Tracked points : 128\n",
      "transforms:  485\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and OpenCV\n",
    "import numpy as np\n",
    "import cv2# Read input video\n",
    "\n",
    "fname = \"../deep-stabilization/dvs/video/s_114_outdoor_running_trail_daytime/ControlCam_20200930_104820.mp4\"\n",
    "cap = cv2.VideoCapture(fname)\n",
    " \n",
    "# Get frame count\n",
    "n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    " \n",
    "# Get width and height of video stream\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    " \n",
    "# Define the codec for output video\n",
    " \n",
    "# Set up output video\n",
    "fps = 30\n",
    "print(w, h)\n",
    "\n",
    "# Read first frame\n",
    "_, prev = cap.read()\n",
    " \n",
    "# Convert frame to grayscale\n",
    "prev_gray = cv2.cvtColor(prev, cv2.COLOR_BGR2GRAY)\n",
    "# prev_gray = (prev_gray&192)|((prev_gray&32)<<1)\n",
    "\n",
    "# Pre-define transformation-store array\n",
    "transforms = np.zeros((n_frames-1, 3), np.float32)\n",
    " \n",
    "for i in range(n_frames-2):\n",
    "    # Detect feature points in previous frame\n",
    "    prev_pts = cv2.goodFeaturesToTrack(prev_gray,\n",
    "                                     maxCorners=400,\n",
    "                                     qualityLevel=0.3,\n",
    "                                     minDistance=20,\n",
    "                                     blockSize=9)\n",
    " \n",
    "    # Read next frame\n",
    "    success, curr = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    " \n",
    "    # Convert to grayscale\n",
    "    curr_gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "    # curr_gray = (curr_gray&192)|((curr_gray&32)<<1)\n",
    " \n",
    "    # Calculate optical flow (i.e. track feature points)\n",
    "    curr_pts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, curr_gray, prev_pts, None)\n",
    " \n",
    "    # Sanity check\n",
    "    assert prev_pts.shape == curr_pts.shape\n",
    " \n",
    "    # Filter only valid points\n",
    "    idx = np.where(status==1)[0]\n",
    "    prev_pts = prev_pts[idx]\n",
    "    curr_pts = curr_pts[idx]\n",
    " \n",
    "    #Find transformation matrix\n",
    "    retval, inliers = cv2.estimateAffine2D(prev_pts, curr_pts)\n",
    " \n",
    "    # Extract traslation\n",
    "    dx = retval[0][2]\n",
    "    dy = retval[1][2]\n",
    " \n",
    "    # Extract rotation angle\n",
    "    da = np.arctan2(retval[1,0], retval[0,0])\n",
    " \n",
    "    # Store transformation\n",
    "    transforms[i] = [dx,dy,da]\n",
    " \n",
    "    # Move to next frame\n",
    "    prev_gray = curr_gray\n",
    " \n",
    "    print(\"Frame: \" + str(i) +  \"/\" + str(n_frames) + \" -  Tracked points : \" + str(len(prev_pts)))\n",
    "  \n",
    "# Compute trajectory using cumulative sum of transformations\n",
    "print(\"transforms: \", len(transforms))\n",
    "trajectory = np.cumsum(transforms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "def movingAverage(curve, radius):\n",
    "    window_size = 2 * radius + 1\n",
    "    # Define the filter\n",
    "    f = np.ones(window_size)/window_size\n",
    "    # Add padding to the boundaries\n",
    "    curve_pad = np.lib.pad(curve, (radius, radius), 'edge')\n",
    "    # Apply convolution\n",
    "    curve_smoothed = np.convolve(curve_pad, f, mode='same')\n",
    "    # Remove padding\n",
    "    curve_smoothed = curve_smoothed[radius:-radius]\n",
    "    # return smoothed curve\n",
    "    return savgol_filter(curve, window_size, 3)\n",
    "    # return curve_smoothed\n",
    "\n",
    "def fixBorder(frame):\n",
    "    s = frame.shape\n",
    "    # Scale the image 4% without moving the center\n",
    "    T = cv2.getRotationMatrix2D((s[1]/2, s[0]/2), 0, 1.04)\n",
    "    frame = cv2.warpAffine(frame, T, (s[1], s[0]))\n",
    "    return frame\n",
    "\n",
    "def smooth(trajectory, SMOOTHING_RADIUS=60):\n",
    "    smoothed_trajectory = np.copy(trajectory)\n",
    "    # Filter the x, y and angle curves\n",
    "    for i in range(3):\n",
    "        smoothed_trajectory[:,i] = movingAverage(trajectory[:,i], radius=SMOOTHING_RADIUS)\n",
    " \n",
    "    return smoothed_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference in smoothed_trajectory and trajectory\n",
    "smoothed_trajectory = smooth(trajectory)\n",
    "difference = smoothed_trajectory - trajectory\n",
    "# median = np.median(np.abs(difference))\n",
    "# new_trajectory = trajectory.copy()\n",
    "# for i, d in enumerate(difference):\n",
    "#     if d[0]>median:\n",
    "#         new_trajectory[i] = smoothed_trajectory[i]\n",
    "    \n",
    "# smoothed_trajectory = smooth(new_trajectory)\n",
    "# difference = smoothed_trajectory - trajectory\n",
    "# # Calculate newer transformation array\n",
    "transforms_smooth = transforms + difference\n",
    "\n",
    "\n",
    "# Reset stream to first frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "frames=[]\n",
    "# Write n_frames-1 transformed frames\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('../video_out.mp4', fourcc, fps, (w, h))\n",
    "for i in range(n_frames-2):\n",
    "    # Read next frame\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Extract transformations from the new transformation array\n",
    "    dx = transforms_smooth[i,0]\n",
    "    dy = transforms_smooth[i,1]\n",
    "    da = transforms_smooth[i,2]\n",
    " \n",
    "    # Reconstruct transformation matrix accordingly to new values\n",
    "    m = np.zeros((2,3), np.float32)\n",
    "    m[0,0] = np.cos(da)\n",
    "    m[0,1] = -np.sin(da)\n",
    "    m[1,0] = np.sin(da)\n",
    "    m[1,1] = np.cos(da)\n",
    "    m[0,2] = dx\n",
    "    m[1,2] = dy\n",
    " \n",
    "    # Apply affine wrapping to the given frame\n",
    "    frame_stabilized = cv2.warpAffine(frame.astype(np.float64)/255, m, (w,h))\n",
    "\n",
    "    # Fix border artifacts\n",
    "    # frame_stabilized = fixBorder(frame_stabilized)\n",
    "\n",
    "    # Write the frame to the file\n",
    "    frame_out = cv2.hconcat([frame.astype(np.float64)/255, frame_stabilized])\n",
    "\n",
    "    # If the image is too big, resize it.\n",
    "    if frame_out.shape[1] > 1920:\n",
    "        frame_out = cv2.resize(frame_out, (frame_out.shape[1]//2, frame_out.shape[0]));\n",
    " \n",
    "    frames.append(frame_out)\n",
    "    out.write((frame_out*255).astype(np.uint8))\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "frames = [torch.from_numpy(frame) for frame in frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = torch.stack(frames)\n",
    "vid.shape\n",
    "from torchvision.io import read_video, read_video_timestamps, write_video\n",
    "write_video(\"../video_out.avi\", vid.flip(3), fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"../video_out.mp4\", width=960, height=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"../video_out.mp4\", width=960, height=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"../stable_video.avi\", width=960, height=540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b14ac9e988f69289b67bb64ec11e6e1cb3880eab5602089907734852574a6011"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
